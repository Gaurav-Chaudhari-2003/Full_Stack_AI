{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Features Extraction from Text\n",
   "id": "7108b9255408bc96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Bag of Words\n",
    "\n",
    "* used for the count occurrence of a word in the sentence.\n",
    "* used in multinomial naive-biased.\n"
   ],
   "id": "74492d84344399e1"
  },
  {
   "cell_type": "code",
   "id": "67d360ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:27:10.090828700Z",
     "start_time": "2026-01-16T14:27:10.071996Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3584194e63a4e302"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:27:10.124044800Z",
     "start_time": "2026-01-16T14:27:10.092827600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define sample sentences (documents)\n",
    "A1 = 'hello and welcome, welcome again'\n",
    "A2 = 'shri love NLP' \n",
    "A3 = 'shri is good boy'"
   ],
   "id": "26ced6b4d536863b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    ### Stopwords: Benefits and Drawbacks\n",
    "\n",
    "**Benefits of Removing Stopwords:**\n",
    "1. **Noise Reduction:** Removes common words (like \"the\", \"is\") that often don't carry significant meaning for the topic.\n",
    "2. **Dimensionality Reduction:** Reduces the number of features, leading to smaller models and faster computation.\n",
    "\n",
    "**Performance Impact Example:**\n",
    "Imagine a dataset with 1,000 documents.\n",
    "*   **With Stopwords:** The vocabulary might contain 5,000 unique words. The resulting matrix is 1,000 x 5,000 (5 million elements).\n",
    "*   **Without Stopwords:** Removing stopwords might reduce the vocabulary to 3,000 words. The matrix becomes 1,000 x 3,000 (3 million elements).\n",
    "*   **Result:**\n",
    "    *   **Memory:** 40% reduction in memory usage for the matrix.\n",
    "    *   **Speed:** Algorithms (like Naive Bayes or Logistic Regression) train significantly faster because they have fewer features to process.\n",
    "\n",
    "**Loss (Drawbacks) of Removing Stopwords:**\n",
    "1. **Loss of Context/Meaning:** Some stopwords can be crucial for meaning (e.g., \"not\" in \"not good\").\n",
    "2. **Structure Loss:** Removes grammatical structure which might be important for some NLP tasks."
   ],
   "id": "af03b2aea74c9e58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:27:10.185112300Z",
     "start_time": "2026-01-16T14:27:10.125045500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize CountVectorizer with English stop words removed\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the model and learn the vocabulary; then transform the data into a document-term matrix\n",
    "vectors = vectorizer.fit_transform([A1,A2,A3])\n",
    "\n",
    "# Get the unique words (features) identified in the data\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the sparse matrix to a dense format for readability\n",
    "print(f\"Sparce matric: {vectors}\")\n",
    "dense = vectors.todense()\n",
    "print(f\"Dense matrix: {dense}\")\n",
    "\n",
    "# Create a DataFrame to visualize the word counts for each document\n",
    "result = pd.DataFrame(dense, columns=feature_names)\n",
    "\n",
    "print(result)"
   ],
   "id": "7ade09f59adb39ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparce matric: <Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 8 stored elements and shape (3, 7)>\n",
      "  Coords\tValues\n",
      "  (0, 2)\t1\n",
      "  (0, 6)\t2\n",
      "  (1, 5)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 0)\t1\n",
      "Dense matrix: [[0 0 1 0 0 0 2]\n",
      " [0 0 0 1 1 1 0]\n",
      " [1 1 0 0 0 1 0]]\n",
      "   boy  good  hello  love  nlp  shri  welcome\n",
      "0    0     0      1     0    0     0        2\n",
      "1    0     0      0     1    1     1        0\n",
      "2    1     1      0     0    0     1        0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "02a047a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:27:10.198621200Z",
     "start_time": "2026-01-16T14:27:10.187113100Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "30ea3ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:27:10.211129400Z",
     "start_time": "2026-01-16T14:27:10.199625100Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TF - IDF\n",
    "\n",
    "* used for getting more details about the data"
   ],
   "id": "ebd729a5f13718da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:27:10.226111100Z",
     "start_time": "2026-01-16T14:27:10.214128300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ],
   "id": "9c0158c8d03f5a27",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:27:10.236134500Z",
     "start_time": "2026-01-16T14:27:10.228110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "A1 = 'hello and welcome, welcome again'\n",
    "A2 = 'shri love NLP'\n",
    "A3 = 'shri is good boy'"
   ],
   "id": "c64349f542935279",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T14:27:10.272386400Z",
     "start_time": "2026-01-16T14:27:10.244136100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize TfidfVectorizer with English stop words removed\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the model to learn vocabulary and transform documents into TF-IDF matrix\n",
    "vectors = vectorizer.fit_transform([A1,A2,A3])\n",
    "\n",
    "# Get the feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert sparse matrix to dense matrix for readability\n",
    "print(f\"Sparce matric: {vectors}\")\n",
    "dense = vectors.todense()\n",
    "print(f\"Dense matrix: {dense}\")\n",
    "\n",
    "# Create DataFrame to view TF-IDF scores\n",
    "result = pd.DataFrame(dense, columns=feature_names)\n",
    "\n",
    "print(result)"
   ],
   "id": "b6fc7e63c9fcffbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparce matric: <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 8 stored elements and shape (3, 7)>\n",
      "  Coords\tValues\n",
      "  (0, 2)\t0.4472135954999579\n",
      "  (0, 6)\t0.8944271909999159\n",
      "  (1, 5)\t0.4736296010332684\n",
      "  (1, 3)\t0.6227660078332259\n",
      "  (1, 4)\t0.6227660078332259\n",
      "  (2, 5)\t0.4736296010332684\n",
      "  (2, 1)\t0.6227660078332259\n",
      "  (2, 0)\t0.6227660078332259\n",
      "Dense matrix: [[0.         0.         0.4472136  0.         0.         0.\n",
      "  0.89442719]\n",
      " [0.         0.         0.         0.62276601 0.62276601 0.4736296\n",
      "  0.        ]\n",
      " [0.62276601 0.62276601 0.         0.         0.         0.4736296\n",
      "  0.        ]]\n",
      "        boy      good     hello      love       nlp     shri   welcome\n",
      "0  0.000000  0.000000  0.447214  0.000000  0.000000  0.00000  0.894427\n",
      "1  0.000000  0.000000  0.000000  0.622766  0.622766  0.47363  0.000000\n",
      "2  0.622766  0.622766  0.000000  0.000000  0.000000  0.47363  0.000000\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
