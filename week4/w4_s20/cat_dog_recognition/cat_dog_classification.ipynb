{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-07T18:39:26.611104100Z",
     "start_time": "2026-01-07T18:39:26.580771800Z"
    }
   },
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dense, Flatten"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### images into the variables",
   "id": "f9095248234cd5d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T18:39:26.676895800Z",
     "start_time": "2026-01-07T18:39:26.614102800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train = ImageDataGenerator(rescale=1./255)\n",
    "test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train.flow_from_directory(\"assets/augmented/train\", target_size=(100, 100), class_mode='binary')\n",
    "test_data = test.flow_from_directory(\"assets/augmented/test/\", target_size=(100, 100), class_mode='binary')"
   ],
   "id": "e181a238dc44384a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 714 images belonging to 2 classes.\n",
      "Found 245 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train the model only on the dog dataset",
   "id": "a44ac2fa701260bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T18:40:12.616824800Z",
     "start_time": "2026-01-07T18:39:26.678900400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(100, 100, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier.fit(train_data, validation_data=test_data, epochs=4)"
   ],
   "id": "b2e2a175aacaf959",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001B[1m23/23\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 503ms/step - accuracy: 0.5000 - loss: 2.4756 - val_accuracy: 0.4980 - val_loss: 0.7253\n",
      "Epoch 2/4\n",
      "\u001B[1m23/23\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 474ms/step - accuracy: 0.6303 - loss: 0.6457 - val_accuracy: 0.6857 - val_loss: 0.5379\n",
      "Epoch 3/4\n",
      "\u001B[1m23/23\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 489ms/step - accuracy: 0.9384 - loss: 0.3517 - val_accuracy: 0.9306 - val_loss: 0.2702\n",
      "Epoch 4/4\n",
      "\u001B[1m23/23\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 478ms/step - accuracy: 0.9804 - loss: 0.1028 - val_accuracy: 1.0000 - val_loss: 0.0587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17c8c182350>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### If score >= 0.5 then Dog else Cat",
   "id": "63c5ce86a15271e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T18:40:12.664865400Z",
     "start_time": "2026-01-07T18:40:12.634334800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(img, classifier):\n",
    "    img = load_img(img, target_size=(100, 100))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    final = classifier.predict(img)\n",
    "    print(final)"
   ],
   "id": "f32b98470a676d75",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T18:40:12.789145100Z",
     "start_time": "2026-01-07T18:40:12.665865400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"assets/augmented/train/dog/dog_0_5.png\"\n",
    "predict(path, classifier)"
   ],
   "id": "f2cee2438070bdf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "[[0.96652794]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T18:40:12.871513100Z",
     "start_time": "2026-01-07T18:40:12.799143200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"assets/augmented/test/cat/cat_0_8322.png\"\n",
    "predict(path, classifier)"
   ],
   "id": "22f6ec8b2166be1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "[[0.01331516]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save Model",
   "id": "f6f046d07cdfee08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T18:59:37.356007800Z",
     "start_time": "2026-01-07T18:59:36.162201700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "keras.saving.save_model(classifier, 'animal_classifier.keras')"
   ],
   "id": "e26d2d019efb3b71",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T19:12:46.055452400Z",
     "start_time": "2026-01-07T19:12:44.687346600Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b1e29f6c7f278d8",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "path should be path-like or io.BytesIO, not <class 'tuple'>",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m test_data:\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     \u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclassifier\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 4\u001B[39m, in \u001B[36mpredict\u001B[39m\u001B[34m(img, classifier)\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpredict\u001B[39m(img, classifier):\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     img = \u001B[43mload_img\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m     img = img_to_array(img)\n\u001B[32m      6\u001B[39m     img = img / \u001B[32m255\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:250\u001B[39m, in \u001B[36mload_img\u001B[39m\u001B[34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001B[39m\n\u001B[32m    248\u001B[39m         img = pil_image.open(io.BytesIO(f.read()))\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    251\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mpath should be path-like or io.BytesIO, not \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    252\u001B[39m     )\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m color_mode == \u001B[33m\"\u001B[39m\u001B[33mgrayscale\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    255\u001B[39m     \u001B[38;5;66;03m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001B[39;00m\n\u001B[32m    256\u001B[39m     \u001B[38;5;66;03m# convert it to an 8-bit grayscale image.\u001B[39;00m\n\u001B[32m    257\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m img.mode \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[33m\"\u001B[39m\u001B[33mL\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mI;16\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mI\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[31mTypeError\u001B[39m: path should be path-like or io.BytesIO, not <class 'tuple'>"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
